{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c75eec7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import cv2\n",
    "from datasets import load_dataset\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "from huggingface_hub import notebook_login\n",
    "import shutil\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "45a69c42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def retrieve_class_images(class_prompt, class_data_dir, num_class_images):\n",
    "    cmd = f\"python /Users/megan.bultema/Documents/diffusers/examples/custom_diffusion/retrieve.py --class_prompt {class_prompt} --class_data_dir {class_data_dir} --num_class_images {num_class_images}\"\n",
    "    subprocess.run(cmd, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0f86a4a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " def create_metadata_csv_and_push_to_hub(root: str, HF_user = 'megantron'):\n",
    "    \"\"\"\n",
    "    Create a metadata.csv file and push it to the huggingface hub for a given image folder and text file. \n",
    "    This function creates a DataFrame with the image and text data from the text file and writes it to \n",
    "    metadata.csv. It also pushes the dataset to the Hugging Face hub.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    root : str\n",
    "        Absolute path to the folder containing download of images using retrieve_class_images()\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    img_folder = root+'/images/'\n",
    "    img_txtfile = root+'/images.txt'\n",
    "    txt_file = root+'/caption.txt'\n",
    "    # create a list of image file names from the folder\n",
    "    img_files = os.listdir(img_folder)\n",
    "\n",
    "    # create an empty list to store the image data\n",
    "    img_data = [x for x in img_files]\n",
    "\n",
    "    # read the text file and split the contents into a list\n",
    "    with open(img_txtfile, 'r') as f:\n",
    "        img_data = f.read().splitlines()\n",
    "\n",
    "    #remove abs path to comply with hugging face upload\n",
    "    img_file = [x.replace(f'{img_folder}','') for x in img_data]\n",
    "\n",
    "    # read the text file and split the contents into a list\n",
    "    with open(txt_file, 'r') as f:\n",
    "        text_data = f.read().splitlines()\n",
    "\n",
    "    \n",
    "    # create a dictionary with the image and text data\n",
    "    data_dict = {'file_name': img_file, 'text': text_data}\n",
    "\n",
    "    # create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data_dict)\n",
    "\n",
    "    df.to_csv(f'{img_folder}/metadata.csv', index = False)\n",
    "    dataset = load_dataset(\"imagefolder\", data_dir=img_folder)\n",
    "    notebook_login()\n",
    "    dataset.push_to_hub(f\"{HF_user}/{root.split('/')[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8d35159f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading real regularization images: 100%|██████████| 20/20 [00:10<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "retrieve_class_images(\"simpsons\", \"/Users/megan.bultema/Documents/image_diffusion/hackingtogether-megan/real_reg/simpsons2\", 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6ac1b86d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70245a2cbf244f8ba67a0b5b38361a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /Users/megan.bultema/.cache/huggingface/datasets/imagefolder/default-708ea032dc8d4150/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e798a95bdeb54e928fdebc103844530e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ea2010b7494a379e36571f8a4852ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90af172731f345ffa76f154fac61f282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /Users/megan.bultema/.cache/huggingface/datasets/imagefolder/default-708ea032dc8d4150/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a542285b4ebc4856855536c42d2b94fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3e07e7914a45458a9b4ff7a64d97e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358c8a94d22845df97d97d1f49fb07a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544797fc29bc4301acf8364113ea6be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79882cb324b14cedac45bb4f219c05f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Deleting unused files from dataset repository:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e493bc71a7441179d142a23ad59e15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_metadata_csv_and_push_to_hub('/Users/megan.bultema/Documents/image_diffusion/hackingtogether-megan/real_reg/AnselAdams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "530f3106",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/accelerator.py:249: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "04/27/2023 18:23:37 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cpu\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "{'variance_type', 'sample_max_value', 'dynamic_thresholding_ratio', 'clip_sample_range', 'thresholding'} was not found in config. Values will be initialized to default values.\n",
      "{'mid_block_only_cross_attention', 'resnet_skip_time_act', 'time_embedding_act_fn', 'cross_attention_norm', 'resnet_out_scale_factor', 'addition_embed_type', 'addition_embed_type_num_heads', 'class_embeddings_concat', 'time_embedding_dim', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.\n",
      "Downloading readme: 100%|██████████| 385/385 [00:00<00:00, 121kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /Users/megan.bultema/.cache/huggingface/datasets/megantron___parquet/megantron--simpsons_20-504940326d3510ba/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|          | 0.00/683k [00:00<?, ?B/s]\u001B[A\n",
      "Downloading data:   8%|▊         | 52.2k/683k [00:00<00:01, 435kB/s]\u001B[A\n",
      "Downloading data: 100%|██████████| 683k/683k [00:00<00:00, 2.19MB/s]\u001B[A\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 482.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/megan.bultema/.cache/huggingface/datasets/megantron___parquet/megantron--simpsons_20-504940326d3510ba/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 833.20it/s]                       \n",
      "04/27/2023 18:23:42 - INFO - __main__ - ***** Running training *****\n",
      "04/27/2023 18:23:42 - INFO - __main__ -   Num examples = 20\n",
      "04/27/2023 18:23:42 - INFO - __main__ -   Num Epochs = 10\n",
      "04/27/2023 18:23:42 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "04/27/2023 18:23:42 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "04/27/2023 18:23:42 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "04/27/2023 18:23:42 - INFO - __main__ -   Total optimization steps = 200\n",
      "Steps:   0%|          | 0/200 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Steps: 100%|██████████| 200/200 [4:28:27<00:00, 80.41s/it, lr=0.0001, step_loss=0.0706]Model weights saved in deliberate_simpsons/pytorch_lora_weights.bin\n",
      "{'mid_block_only_cross_attention', 'resnet_skip_time_act', 'time_embedding_act_fn', 'cross_attention_norm', 'resnet_out_scale_factor', 'addition_embed_type', 'addition_embed_type_num_heads', 'class_embeddings_concat', 'time_embedding_dim', 'encoder_hid_dim'} was not found in config. Values will be initialized to default values.\n",
      "/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py\", line 861, in <module>\n",
      "    main()\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py\", line 840, in main\n",
      "    images.append(pipeline(args.validation_prompt, num_inference_steps=30, generator=generator).images[0])\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 626, in __call__\n",
      "    self.check_inputs(\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 493, in check_inputs\n",
      "    raise ValueError(\n",
      "ValueError: Provide either `prompt` or `prompt_embeds`. Cannot leave both `prompt` and `prompt_embeds` undefined.\n",
      "Steps: 100%|██████████| 200/200 [4:28:34<00:00, 80.57s/it, lr=0.0001, step_loss=0.0706]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/bin/accelerate\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 923, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 579, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/Users/megan.bultema/opt/anaconda3/envs/diffpy2/bin/python3.10', '/Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py', '--pretrained_model_name_or_path=./converted_model_deliberate', '--dataset_name=megantron/simpsons_20', '--caption_column=text', '--resolution=512', '--random_flip', '--train_batch_size=1', '--num_train_epochs=10', '--checkpointing_steps=500', '--learning_rate=1e-04', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--seed=42', '--output_dir=deliberate_simpsons']' returned non-zero exit status 1.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'export MODEL_NAME=\"./converted_model_deliberate\"\\nexport DATASET_NAME=\"megantron/simpsons_20\"\\nexport OUTPUT_DIR=\"deliberate_simpsons\"\\n\\naccelerate launch  /Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py \\\\\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\\\\n  --dataset_name=$DATASET_NAME --caption_column=\"text\" \\\\\\n  --resolution=512 --random_flip \\\\\\n  --train_batch_size=1 \\\\\\n  --num_train_epochs=10 --checkpointing_steps=500 \\\\\\n  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\\\\n  --seed=42 \\\\\\n  --output_dir=$OUTPUT_DIR \\\\\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mCalledProcessError\u001B[0m                        Traceback (most recent call last)",
      "Input \u001B[0;32mIn [108]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_cell_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbash\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mexport MODEL_NAME=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./converted_model_deliberate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mexport DATASET_NAME=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmegantron/simpsons_20\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43mexport OUTPUT_DIR=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdeliberate_simpsons\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43maccelerate launch  /Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --pretrained_model_name_or_path=$MODEL_NAME \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --dataset_name=$DATASET_NAME --caption_column=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtext\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --resolution=512 --random_flip \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --train_batch_size=1 \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --num_train_epochs=10 --checkpointing_steps=500 \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --learning_rate=1e-04 --lr_scheduler=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconstant\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m --lr_warmup_steps=0 \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --seed=42 \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m  --output_dir=$OUTPUT_DIR \u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2358\u001B[0m, in \u001B[0;36mInteractiveShell.run_cell_magic\u001B[0;34m(self, magic_name, line, cell)\u001B[0m\n\u001B[1;32m   2356\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m   2357\u001B[0m     args \u001B[38;5;241m=\u001B[39m (magic_arg_s, cell)\n\u001B[0;32m-> 2358\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2359\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/IPython/core/magics/script.py:153\u001B[0m, in \u001B[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001B[0;34m(line, cell)\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    152\u001B[0m     line \u001B[38;5;241m=\u001B[39m script\n\u001B[0;32m--> 153\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshebang\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/IPython/core/magics/script.py:305\u001B[0m, in \u001B[0;36mScriptMagics.shebang\u001B[0;34m(self, line, cell)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m args\u001B[38;5;241m.\u001B[39mraise_error \u001B[38;5;129;01mand\u001B[39;00m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001B[39;00m\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001B[39;00m\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001B[39;00m\n\u001B[1;32m    304\u001B[0m     rc \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m9\u001B[39m\n\u001B[0;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CalledProcessError(rc, cell)\n",
      "\u001B[0;31mCalledProcessError\u001B[0m: Command 'b'export MODEL_NAME=\"./converted_model_deliberate\"\\nexport DATASET_NAME=\"megantron/simpsons_20\"\\nexport OUTPUT_DIR=\"deliberate_simpsons\"\\n\\naccelerate launch  /Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py \\\\\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\\\\n  --dataset_name=$DATASET_NAME --caption_column=\"text\" \\\\\\n  --resolution=512 --random_flip \\\\\\n  --train_batch_size=1 \\\\\\n  --num_train_epochs=10 --checkpointing_steps=500 \\\\\\n  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\\\\n  --seed=42 \\\\\\n  --output_dir=$OUTPUT_DIR \\\\\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export MODEL_NAME=\"./converted_model_deliberate\"\n",
    "export DATASET_NAME=\"megantron/AnselAdams\"\n",
    "export OUTPUT_DIR=\"deliberate_AnselAdams\"\n",
    "\n",
    "accelerate launch  /Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --dataset_name=$DATASET_NAME --caption_column=\"text\" \\\n",
    "  --resolution=512 --random_flip \\\n",
    "  --train_batch_size=1 \\\n",
    "  --num_train_epochs=10 --checkpointing_steps=500 \\\n",
    "  --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
    "  --seed=42 \\\n",
    "  --output_dir=$OUTPUT_DIR \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaec6f80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_text_to_image_lora(MODEL_NAME, DATASET_NAME, OUTPUT_DIR):\n",
    "    \"\"\"\n",
    "    Trains a text-to-image generation model using the specified parameters.\n",
    "\n",
    "    Args:\n",
    "        MODEL_NAME (str): The name or path of the pre-trained model to use.\n",
    "        DATASET_NAME (str): The name or path of the dataset to use.\n",
    "        OUTPUT_DIR (str): The output directory to save the trained model to.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Set environment variables\n",
    "    os.environ[\"MODEL_NAME\"] = MODEL_NAME\n",
    "    os.environ[\"DATASET_NAME\"] = DATASET_NAME\n",
    "    os.environ[\"OUTPUT_DIR\"] = OUTPUT_DIR\n",
    "\n",
    "    # Launch training script\n",
    "    !accelerate launch /Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
    "        --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "        --dataset_name=$DATASET_NAME --caption_column=\"text\" \\\n",
    "        --resolution=512 --random_flip \\\n",
    "        --train_batch_size=1 \\\n",
    "        --num_train_epochs=10 --checkpointing_steps=500 \\\n",
    "        --learning_rate=1e-04 --lr_scheduler=\"constant\" --lr_warmup_steps=0 \\\n",
    "        --seed=42 \\\n",
    "        --output_dir=$OUTPUT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e63e0908",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/accelerator.py:249: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "05/05/2023 13:44:07 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cpu\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "{'dynamic_thresholding_ratio', 'thresholding', 'variance_type', 'sample_max_value', 'clip_sample_range'} was not found in config. Values will be initialized to default values.\n",
      "{'cross_attention_norm', 'resnet_out_scale_factor', 'addition_embed_type', 'time_embedding_dim', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'encoder_hid_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'time_embedding_act_fn'} was not found in config. Values will be initialized to default values.\n",
      "Downloading readme: 100%|███████████████████████| 398/398 [00:00<00:00, 139kB/s]\n",
      "Downloading and preparing dataset None/None to /Users/megan.bultema/.cache/huggingface/datasets/megantron___parquet/megantron--simpsons_captions-21db4a31475a0f49/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n",
      "Downloading data files:   0%|                             | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                             | 0.00/13.6M [00:00<?, ?B/s]\u001B[A\n",
      "Downloading data:   1%|▏                    | 126k/13.6M [00:00<00:12, 1.09MB/s]\u001B[A\n",
      "Downloading data:   4%|▉                    | 583k/13.6M [00:00<00:04, 3.01MB/s]\u001B[A\n",
      "Downloading data:  10%|██                  | 1.42M/13.6M [00:00<00:02, 5.37MB/s]\u001B[A\n",
      "Downloading data:  17%|███▍                | 2.37M/13.6M [00:00<00:01, 6.99MB/s]\u001B[A\n",
      "Downloading data:  30%|█████▉              | 4.04M/13.6M [00:00<00:00, 10.4MB/s]\u001B[A\n",
      "Downloading data:  42%|████████▎           | 5.68M/13.6M [00:00<00:00, 12.4MB/s]\u001B[A\n",
      "Downloading data:  52%|██████████▍         | 7.13M/13.6M [00:00<00:00, 13.1MB/s]\u001B[A\n",
      "Downloading data:  67%|█████████████▍      | 9.17M/13.6M [00:00<00:00, 15.4MB/s]\u001B[A\n",
      "Downloading data: 100%|████████████████████| 13.6M/13.6M [00:01<00:00, 13.1MB/s]\u001B[A\n",
      "Downloading data files: 100%|█████████████████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "Extracting data files: 100%|█████████████████████| 1/1 [00:00<00:00, 829.24it/s]\n",
      "Dataset parquet downloaded and prepared to /Users/megan.bultema/.cache/huggingface/datasets/megantron___parquet/megantron--simpsons_captions-21db4a31475a0f49/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n",
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 214.55it/s]\n",
      "05/05/2023 13:44:15 - INFO - __main__ - ***** Running training *****\n",
      "05/05/2023 13:44:15 - INFO - __main__ -   Num examples = 200\n",
      "05/05/2023 13:44:15 - INFO - __main__ -   Num Epochs = 10\n",
      "05/05/2023 13:44:15 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "05/05/2023 13:44:15 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "05/05/2023 13:44:15 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "05/05/2023 13:44:15 - INFO - __main__ -   Total optimization steps = 2000\n",
      "Steps:   0%|                                           | 0/2000 [00:00<?, ?it/s][W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "Steps:   0%|   | 6/2000 [07:58<44:06:33, 79.64s/it, lr=0.0001, step_loss=0.0057]/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/PIL/Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Steps:  25%|▎| 500/2000 [11:06:10<33:04:14, 79.37s/it, lr=0.0001, step_loss=0.1305/06/2023 00:50:26 - INFO - accelerate.accelerator - Saving current state to deliberate_simpsons200/checkpoint-500\n",
      "05/06/2023 00:50:26 - INFO - accelerate.checkpointing - Model weights saved in deliberate_simpsons200/checkpoint-500/pytorch_model.bin\n",
      "05/06/2023 00:50:26 - INFO - accelerate.checkpointing - Optimizer state saved in deliberate_simpsons200/checkpoint-500/optimizer.bin\n",
      "05/06/2023 00:50:26 - INFO - accelerate.checkpointing - Scheduler state saved in deliberate_simpsons200/checkpoint-500/scheduler.bin\n",
      "05/06/2023 00:50:26 - INFO - accelerate.checkpointing - Random states saved in deliberate_simpsons200/checkpoint-500/random_states_0.pkl\n",
      "05/06/2023 00:50:26 - INFO - __main__ - Saved state to deliberate_simpsons200/checkpoint-500\n",
      "Steps:  50%|▌| 1000/2000 [22:07:35<22:00:43, 79.24s/it, lr=0.0001, step_loss=0.005/06/2023 11:51:50 - INFO - accelerate.accelerator - Saving current state to deliberate_simpsons200/checkpoint-1000\n",
      "05/06/2023 11:51:50 - INFO - accelerate.checkpointing - Model weights saved in deliberate_simpsons200/checkpoint-1000/pytorch_model.bin\n",
      "05/06/2023 11:51:50 - INFO - accelerate.checkpointing - Optimizer state saved in deliberate_simpsons200/checkpoint-1000/optimizer.bin\n",
      "05/06/2023 11:51:50 - INFO - accelerate.checkpointing - Scheduler state saved in deliberate_simpsons200/checkpoint-1000/scheduler.bin\n",
      "05/06/2023 11:51:50 - INFO - accelerate.checkpointing - Random states saved in deliberate_simpsons200/checkpoint-1000/random_states_0.pkl\n",
      "05/06/2023 11:51:50 - INFO - __main__ - Saved state to deliberate_simpsons200/checkpoint-1000\n",
      "Steps:  75%|▊| 1500/2000 [33:11:02<11:00:54, 79.31s/it, lr=0.0001, step_loss=0.005/06/2023 22:55:17 - INFO - accelerate.accelerator - Saving current state to deliberate_simpsons200/checkpoint-1500\n",
      "05/06/2023 22:55:17 - INFO - accelerate.checkpointing - Model weights saved in deliberate_simpsons200/checkpoint-1500/pytorch_model.bin\n",
      "05/06/2023 22:55:17 - INFO - accelerate.checkpointing - Optimizer state saved in deliberate_simpsons200/checkpoint-1500/optimizer.bin\n",
      "05/06/2023 22:55:17 - INFO - accelerate.checkpointing - Scheduler state saved in deliberate_simpsons200/checkpoint-1500/scheduler.bin\n",
      "05/06/2023 22:55:17 - INFO - accelerate.checkpointing - Random states saved in deliberate_simpsons200/checkpoint-1500/random_states_0.pkl\n",
      "05/06/2023 22:55:17 - INFO - __main__ - Saved state to deliberate_simpsons200/checkpoint-1500\n",
      "Steps: 100%|█| 2000/2000 [44:12:29<00:00, 79.31s/it, lr=0.0001, step_loss=0.004005/07/2023 09:56:44 - INFO - accelerate.accelerator - Saving current state to deliberate_simpsons200/checkpoint-2000\n",
      "05/07/2023 09:56:44 - INFO - accelerate.checkpointing - Model weights saved in deliberate_simpsons200/checkpoint-2000/pytorch_model.bin\n",
      "05/07/2023 09:56:44 - INFO - accelerate.checkpointing - Optimizer state saved in deliberate_simpsons200/checkpoint-2000/optimizer.bin\n",
      "05/07/2023 09:56:44 - INFO - accelerate.checkpointing - Scheduler state saved in deliberate_simpsons200/checkpoint-2000/scheduler.bin\n",
      "05/07/2023 09:56:44 - INFO - accelerate.checkpointing - Random states saved in deliberate_simpsons200/checkpoint-2000/random_states_0.pkl\n",
      "05/07/2023 09:56:44 - INFO - __main__ - Saved state to deliberate_simpsons200/checkpoint-2000\n",
      "Steps: 100%|█| 2000/2000 [44:12:29<00:00, 79.31s/it, lr=0.0001, step_loss=0.0729Model weights saved in deliberate_simpsons200/pytorch_lora_weights.bin\n",
      "/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "{'cross_attention_norm', 'resnet_out_scale_factor', 'addition_embed_type', 'time_embedding_dim', 'resnet_skip_time_act', 'addition_embed_type_num_heads', 'encoder_hid_dim', 'class_embeddings_concat', 'mid_block_only_cross_attention', 'time_embedding_act_fn'} was not found in config. Values will be initialized to default values.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py\", line 861, in <module>\n",
      "    main()\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py\", line 840, in main\n",
      "    images.append(pipeline(args.validation_prompt, num_inference_steps=30, generator=generator).images[0])\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 626, in __call__\n",
      "    self.check_inputs(\n",
      "  File \"/Users/megan.bultema/Documents/diffusers/src/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 493, in check_inputs\n",
      "    raise ValueError(\n",
      "ValueError: Provide either `prompt` or `prompt_embeds`. Cannot leave both `prompt` and `prompt_embeds` undefined.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 100%|█| 2000/2000 [44:12:32<00:00, 79.58s/it, lr=0.0001, step_loss=0.0729\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/bin/accelerate\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 45, in main\n",
      "    args.func(args)\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 923, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 579, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/Users/megan.bultema/opt/anaconda3/envs/diffpy2/bin/python3.10', '/Users/megan.bultema/Documents/diffusers/examples/text_to_image/train_text_to_image_lora.py', '--pretrained_model_name_or_path=./converted_model_deliberate', '--dataset_name=megantron/simpsons_captions', '--caption_column=text', '--resolution=512', '--random_flip', '--train_batch_size=1', '--num_train_epochs=10', '--checkpointing_steps=500', '--learning_rate=1e-04', '--lr_scheduler=constant', '--lr_warmup_steps=0', '--seed=42', '--output_dir=deliberate_simpsons200']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "train_text_to_image_lora(\"./converted_model_deliberate\",\"megantron/simpsons_captions\",\"deliberate_simpsons200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9676fe2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_test_images(model_path: str, num_images, prompt, n_prompt) -> None:\n",
    "    \"\"\"\n",
    "    Generate 5 test images using StableDiffusionPipeline and save them to a local directory named test_images.\n",
    "\n",
    "    Args:\n",
    "    - model_path (str): The path to the pre-trained model directory.\n",
    "    num_images (int): Number of test images to generate\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # check if test_images directory exists, if it does, remove it and create a new one\n",
    "    if os.path.exists(\"test_images\"):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(\"test_images\")\n",
    "\n",
    "    # create StableDiffusionPipeline object and load attention processes\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\"./converted_model_deliberate\")\n",
    "    pipe.unet.load_attn_procs(model_path)\n",
    "    pipe.to(\"mps\")\n",
    "\n",
    "    # generate 5 test images and save them to test_images directory\n",
    "    for i in range(num_images):\n",
    "\n",
    "        image = pipe(prompt, negative_prompt=n_prompt, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
    "        save_header = model_path.split('/')[-1]\n",
    "        image.save(f\"test_images/{save_header}_test{i}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "44f2ad2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3964dd60738741e897faa31deff66506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b3bdc8ec964a828a377e50d20e419d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9714e751644538979536933335835d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c5b3e2d6c0484aa364f6bd0d9a19eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f026c2f6006949388d7bb8be1e78ca15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = \"\"\"(Cinematic photo: 1. 3), rat magician, directional look, \n",
    "octane render, ultra detailed, wide angle full body, 8k, ultra-detailed, (backlight:1. 2) intricate, style-empire\"\"\"\n",
    "n = \"\"\"nrealfixer, nfixer, nartfixer, illustration, drawing, 3d, b&w, \n",
    "(deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, \n",
    "wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), \n",
    "disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation\"\"\"\n",
    "generate_test_images(\"./deliberate_simpsons\", 5, p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d3c23b2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bca5d6ae22745608f47ab1b77a599a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218cb4687ca84bd8baa44fcf451066c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0da66d67444452a20e9022bf912ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b202116ca3b47de90792becbc841877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02623afc4cc645f98e4584d874d90929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = \"\"\" Mountains style Ansel Adams photography octane render, ultra detailed, wide angle full body, 8k, ultra-detailed, intricate, \"\"\"\n",
    "n = \"\"\"nrealfixer, nfixer, nartfixer, illustration, drawing, 3d, b&w, \n",
    "(deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, \n",
    "wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), \n",
    "disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation\"\"\"\n",
    "generate_test_images(\"./deliberate_AnselAdams\", 5, p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754a8eef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan.bultema/opt/anaconda3/envs/diffpy2/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c6c345e1d4457bb4fea7d6c388296a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55d90f1bff44546a9a9b30a766628ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccee95f6862483b8ef8e975266eeb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2691be4adfb443af9d2fddceaae0713e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71995a89ad141f889808a69207b8db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = \"\"\" Bart Simpson as a military comander, ultra detailed, wide angle full body, 8k, ultra-detailed, intricate, \"\"\"\n",
    "n = \"\"\"nrealfixer, nfixer, nartfixer, illustration, drawing, 3d, b&w, \n",
    "(deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, \n",
    "wrong anatomy, extra limb, missing limb, floating limbs, (mutated hands and fingers:1.4), \n",
    "disconnected limbs, mutation, mutated, ugly, disgusting, blurry, amputation\"\"\"\n",
    "generate_test_images(\"./deliberate_simpsons200\", 5, p, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b985087",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}